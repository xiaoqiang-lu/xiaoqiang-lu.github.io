<!DOCTYPE html>
<!-- saved from url=(0039)http://www.cbsr.ia.ac.cn/users/sfzhang/ -->
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1.0">
  <meta name="author" content="Lu Xiaoqiang">
  <title>Xiaoqiang Lu's Homepage</title>

  <!-- CSS  -->
  <link href="./data/materialize.min.css" type="text/css" rel="stylesheet" media="screen,projection">
  <link href="./data/aos.css" type="text/css" rel="stylesheet" media="screen,projection">
  <link href="./data/style.css" type="text/css" rel="stylesheet" media="screen,projection">

  <link rel="shortcut icon" href="./data/xiaoqianglu.png">
<script type="text/javascript" src="./data/jquery-1.12.4.min.js.下载"></script><style>@-moz-keyframes nodeInserted{from{opacity:0.99;}to{opacity:1;}}@-webkit-keyframes nodeInserted{from{opacity:0.99;}to{opacity:1;}}@-o-keyframes nodeInserted{from{opacity:0.99;}to{opacity:1;}}@keyframes nodeInserted{from{opacity:0.99;}to{opacity:1;}}embed,object{animation-duration:.001s;-ms-animation-duration:.001s;-moz-animation-duration:.001s;-webkit-animation-duration:.001s;-o-animation-duration:.001s;animation-name:nodeInserted;-ms-animation-name:nodeInserted;-moz-animation-name:nodeInserted;-webkit-animation-name:nodeInserted;-o-animation-name:nodeInserted;}</style></head>
<body data-aos-easing="ease" data-aos-duration="400" data-aos-delay="0">
  
  <div class="navbar-fixed">

    <nav class="white">
      <div class="nav-wrapper container"><a id="logo-container" href="https://xiaoqiang-lu.github.io/#" class="brand-logo"></a>
        <ul class="left">
          <li><a class="nav-item waves-effect waves-light active" href="https://xiaoqiang-lu.github.io/#home">Home</a></li>
          <li><a class="nav-item waves-effect waves-light" href="https://xiaoqiang-lu.github.io/#biography">Biography</a></li>
          <li><a class="nav-item waves-effect waves-light" href="https://xiaoqiang-lu.github.io/#publications">Publications</a></li>
          <li><a class="nav-item waves-effect waves-light" href="https://xiaoqiang-lu.github.io/#contests">Contests</a></li>
          <li><a class="nav-item waves-effect waves-light" href="https://xiaoqiang-lu.github.io/#education">Education</a></li>
          <li><a class="nav-item waves-effect waves-light" href="https://xiaoqiang-lu.github.io/#awards">Awards</a></li>
        </ul>
        </ul>

      </div>
    </nav>
  </div>
  

<!--==========================================
                   Profile
===========================================-->

<div class="parallax-container scrollspy" id="home">


  <div class="container row cover-block">

    <div class="profile-image-block col s12 m12 l4 center">
        <img class="responsive-img profile-photo z-depth-2" src="./data/xq.jpg" style="width:300px;height:450px;" align="center">
    </div>

    <div class="profile-content-block col s12 m12 l8">
        <h5 class="profile-name"><font color="#000000"><b>Xiaoqiang Lu (路小强)</b></font></h5>

        <hr>
        <h5 class="profile-link"><font color="#000000"><b>Ph.D. Candidate at IPIU, School of Artificial Intelligence, Xidian University</b></font></h5>

        <h5 class="profile-link"><font color="#000000"><b>Address: No.2,South Taibai Road, Hi-Tech Development Zone, Xi'an, Shaanxi, China</b></font></h5>

        <h5 class="profile-link"><font color="#000000"><b>Email: luxiaoqiang5903@163.com, xqlu@stu.xidian.edu.cn</b></font></h5>

        <h1></h1>

        <a href="https://scholar.google.com/citations?user=u8fIK3cAAAAJ&hl=en" target="_blank"><img class="responsive-img social-photo " src="./data/gs.png"></a>

        <a href="https://github.com/xiaoqiang-lu" target="_blank"><img class="responsive-img social-photo " src="./data/github.png"></a>

        <a href="https://www.zhihu.com/people/lu-xiao-ba-ba" target="_blank"><img class="responsive-img social-photo " src="./data/zhihu.png"></a>

    </div>

  </div>

</div>


<!--==========================================
                   About
===========================================-->
<div class="section about-section scrollspy" id="biography">

  <div class="row container">
    <br><br>
    <div class="row">
      <div class="title">Biography</div>
      <hr>
    </div>
    
    <div class="row">
      <p>
        Xiaoqiang Lu is currently pursuing the Ph.D. degree with the <a href="https://ipiu.xidian.edu.cn/">Key Laboratory of Intelligent Perception and Image Understanding of Ministry of Education</a>, <a href="https://sai.xidian.edu.cn/">School of Artificial Intelligence</a>, <a href="https://www.xidian.edu.cn/">Xidian University</a>, supervised by Prof. <a href="https://scholar.google.com/citations?user=FZbrL2YAAAAJ&hl=zh-CN">Licheng Jiao</a></li>. Prior to this, he received his B.S. degree in Information Countermeasure Technique from Xidian University in 2020.
      </p>
      <p>
        Xiaoqiang Lu's research interests include remote sensing data interpretation, computer vision, machine learning, multi-modal understanding, and foundation models.
      </p>
  </div>
</div>




<div class="section publications-section scrollspy" id="publications">

  <div class="row container">
    <div class="row">
      <div class="title">Publications</div>
      <hr>
    </div>

    <div class="row">
      <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <img class="responsive-img" src="./data/RRSECS.png" style="width:320px;height:160px;" align="center">
      </div>

      <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
        <div class="paper-title"><a href="https://xiaoqiang-lu.github.io/">RRSECS: Referring Remote Sensing Expression Comprehension and Segmentation</a></div>
        <div class="paper-author"><font color="#000000"><b>Xiaoqiang Lu</b></font>, Long Sun, Lingling Li, Licheng Jiao, Yuting Yang, Zhongjian Huang, Jinming Chai, Xu Liu, Fang Liu, Wenping Ma, Shuyuan Yang</div>
        <div class="paper-conf"><em> IEEE Geoscience and Remote Sensing Magazine (<font color="#000000"><b>GRSM</b></font>)</em>, 2025.</div>
      </div>
    </div>

    <hr class="publication-hr">

    <div class="row">
      <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <img class="responsive-img" src="./data/UMCL.png" style="width:320px;height:160px;" align="center">
      </div>

      <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
        <div class="paper-title"><a href="https://ieeexplore.ieee.org/abstract/document/10891590">Uncertainty-aware Semi-supervised Learning Segmentation for Remote Sensing Images</a></div>
        <div class="paper-author"><font color="#000000"><b>Xiaoqiang Lu</b></font>, Lingling Li, Licheng Jiao, Xu Liu, Fang Liu, Wenping Ma, Shuyuan Yang</div>
        <div class="paper-conf"><em> IEEE Transactions on Multimedia (<font color="#000000"><b>TMM</b></font>)</em>, 2025.</div>
      </div>
    </div>

    <hr class="publication-hr">

    <div class="row">
      <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <img class="responsive-img" src="./data/Speed.png" style="width:320px;height:160px;" align="center">
      </div>

      <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
        <div class="paper-title"><a href="https://ieeexplore.ieee.org/abstract/document/10464380">Self Pseudo Entropy Knowledge Distillation for Semi-Supervised Semantic Segmentation</a></div>
        <div class="paper-author"><font color="#000000"><b>Xiaoqiang Lu</b></font>, Licheng Jiao, Lingling Li, Fang Liu, Xu Liu, Shuyuan Yang</div>
        <div class="paper-conf"><em> IEEE Transactions on Circuits and Systems for Video Technology (<font color="#000000"><b>TCSVT</b></font>)</em>, 2024.</div>
      </div>
    </div>

    <hr class="publication-hr">

    <div class="row">
        <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
            <img class="responsive-img" src="./data/MTSN.png" style="width:320px;height:160px;" align="center">
        </div>

        <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <div class="paper-title"><a href="https://ieeexplore.ieee.org/abstract/document/10642039">Multimodal Segformer for Flood Rapid Mapping with Sentinel-2 Data</a></div>
          <div class="paper-author"><font color="#000000"><b>Xiaoqiang Lu</b></font>, Tong Gou, Zhongjian Huang, Yuting Yang, Licheng Jiao, Lingling Li, Xu Liu, Fang Liu</div>
          <div class="paper-conf">In <em> IEEE International Geoscience and Remote Sensing Symposium (<font color="#000000"><b>IGARSS</b></font>)</em>, Athens, Greece, 2024.</div>
        </div>
      </div>

    <hr class="publication-hr">

    <div class="row">
      <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <img class="responsive-img" src="./data/brain_inspired.png" style="width:320px;height:160px;" align="center">
      </div>

      <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
        <div class="paper-title"><a href="https://ieeexplore.ieee.org/abstract/document/10254282">Brain-inspired Remote Sensing Foundation Models and Open Problems: A Comprehensive Survey</a></div>
        <div class="paper-author">Licheng Jiao, Zhongjian Huang, <font color="#000000"><b>Xiaoqiang Lu</b></font>, Xu Liu, Yuting Yang, Jiaxuan Zhao, Jinyue Zhang, Biao Hou, Shuyuan Yang, Fang Liu, Wenping Ma, Lingling Li <em>et al</em></div>
        <div class="paper-conf"><em> IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing (<font color="#000000"><b>JSTARS</b></font>)</em>, 2023.</div>
      </div>
    </div>

    <hr class="publication-hr">

        <div class="row">
      <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <img class="responsive-img" src="./data/JSTARS_DFC23.png" style="width:320px;height:160px;" align="center">
      </div>

      <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
        <div class="paper-title"><a href="https://ieeexplore.ieee.org/abstract/document/10535214">Large-Scale Fine-Grained Building Classification and Height Estimation for Semantic Urban Reconstruction: Outcome of the 2023 IEEE GRSS Data Fusion Contest</a></div>
        <div class="paper-author">Guozhang Liu <em>et al</em>, <font color="#000000"><b>Xiaoqiang Lu</b></font>, Licheng Jiao <em>et al</em>, Xian Sun, Claudio Persello, Ronny Hänsch</div>
        <div class="paper-conf"><em> IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing (<font color="#000000"><b>JSTARS</b></font>)</em>, 2023.</div>
      </div>
    </div>

    <hr class="publication-hr">

    <div class="row">
        <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
            <img class="responsive-img" src="./data/tcn.png" style="width:320px;height:160px;" align="center">
        </div>

        <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <div class="paper-title"><a href="https://ieeexplore.ieee.org/document/10281514">Trident Cooperation Network for Building Extraction and Height Estimation</a></div>
          <div class="paper-author"><font color="#000000"><b>Xiaoqiang Lu</b></font>, Licheng Jiao, Qiong Liu, Lingling Li, Fang Liu, Xu Liu, Yuting Yang</div>
          <div class="paper-conf">In <em> IEEE International Geoscience and Remote Sensing Symposium (<font color="#000000"><b>IGARSS</b></font>)</em>, California, USA, 2023.</div>
        </div>
      </div>

    <hr class="publication-hr">

    <div class="row">
        <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
            <img class="responsive-img" src="./data/adaptive.png" style="width:320px;height:160px;" align="center">
        </div>

        <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <div class="paper-title"><a href="https://ieeexplore.ieee.org/document/10281473">A Strong Vision Transformer Adapter with Adaptive Thresholding for fine-Grained Building Classification</a></div>
          <div class="paper-author"><font color="#000000"><b>Xiaoqiang Lu</b></font>, Licheng Jiao, Qiong Liu, Lingling Li, Fang Liu, Xu Liu, Yuting Yang</div>
          <div class="paper-conf">In <em> IEEE International Geoscience and Remote Sensing Symposium (<font color="#000000"><b>IGARSS</b></font>)</em>, California, USA, 2023.</div>
        </div>
      </div>

    <hr class="publication-hr">

    <div class="row">
        <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
            <img class="responsive-img" src="./data/wscl.png" style="width:320px;height:160px;" align="center">
        </div>

        <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <div class="paper-title"><a href="https://ieeexplore.ieee.org/abstract/document/10114409">Weak-to-Strong Consistency Learning for Semisupervised Image Segmentation</a></div>
          <div class="paper-author"><font color="#000000"><b>Xiaoqiang Lu</b></font>, Licheng Jiao, Lingling Li, Fang Liu, Xu Liu, Shuyuan Yang, Zhixi Feng, and Puhua Chen</div>
          <div class="paper-conf"><em>IEEE Transactions on Geoscience and Remote Sensing (<font color="#000000"><b>TGRS</b></font>)</em>, 2023.</div>
          <div>
            <a href="https://github.com/xiaoqiang-lu/WSCL" target="_blank"><img src="https://img.shields.io/github/stars/xiaoqiang-lu/WSCL?style=social" /></a>
          </div>
        </div>
      </div>

    <hr class="publication-hr">

    <div class="row">
        <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
            <img class="responsive-img" src="./data/lsst.png" style="width:320px;height:160px;" align="center">
        </div>

        <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <div class="paper-title"><a href="https://ieeexplore.ieee.org/abstract/document/9943552">Simple and Efficient: A Semisupervised Learning Framework for Remote Sensing Image Semantic Segmentation</a></div>
          <div class="paper-author"><font color="#000000"><b>Xiaoqiang Lu</b></font>, Licheng Jiao, Fang Liu, Shuyuan Yang, Xu Liu, Zhixi Feng, Lingling Li, and Puhua Chen</div>
          <div class="paper-conf"><em>IEEE Transactions on Geoscience and Remote Sensing (<font color="#000000"><b>TGRS</b></font>)</em>, 2022.</div>
          <div>
            <a href="https://github.com/xiaoqiang-lu/LSST" target="_blank"><img src="https://img.shields.io/github/stars/xiaoqiang-lu/LSST?style=social" /></a>
          </div>
        </div>
      </div>

    <hr class="publication-hr">

    <div class="row">
        <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
            <img class="responsive-img" src="./data/aprst.png" style="width:320px;height:160px;" align="center">
        </div>

        <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <div class="paper-title"><a href="https://ieeexplore.ieee.org/document/9884933">Semi-Supervised Landcover Classification with Adaptive Pixel-Rebalancing Self-Training</a></div>
          <div class="paper-author"><font color="#000000"><b>Xiaoqiang Lu</b></font>, Guojin Cao, Tong Gou</div>
          <div class="paper-conf">In <em> IEEE International Geoscience and Remote Sensing Symposium (<font color="#000000"><b>IGARSS</b></font>)</em>, Kuala Lumpur, Malaysia, 2022.</div>
        </div>
      </div>

    <hr class="publication-hr">

  </div>


</div>


<div class="section contests-section scrollspy" id="contests">

  <div class="row container">
    <div class="row">
      <div class="title">Contests</div>
      <hr>
    </div>

    <div class="row">
      <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <img class="responsive-img" src="./data/pbdl.png" style="width:320px;height:160px;" align="center">
      </div>

      <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
        <div class="paper-title"><a href="https://pbdl-ws.github.io/pbdl2024/leaderboard.html">CVPR 2024 PBDL Challenge</a> <img class="responsive-img icon" src="./data/1.png"> </div>
          <div class="paper-task">Track 3-1: Low-light Object Detection</div>

        <div class="paper-author"><font color="#000000"><b>Xiaoqiang Lu</b></font>, Licheng Jiao, Fang Liu, <em>et al</em></div>
        <div class="paper-conf"><em><font color="#000000"><b>1st Place</b></font> In Proceedings of the IEEE Computer Vision and Pattern Recognition (<font color="#000000"><b>CVPR</b></font>) Workshops, 2024</em></div>
      </div>
    </div>

    <hr class="publication-hr">

    <div class="row">
      <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <img class="responsive-img" src="./data/pbdl.png" style="width:320px;height:160px;" align="center">
      </div>

      <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
        <div class="paper-title"><a href="https://pbdl-ws.github.io/pbdl2024/leaderboard.html">CVPR 2024 PBDL Challenge</a> <img class="responsive-img icon" src="./data/1.png"> </div>
          <div class="paper-task">Track 3-2: Low-light Instance Segmentation</div>

        <div class="paper-author"><font color="#000000"><b>Xiaoqiang Lu</b></font>, Licheng Jiao, Fang Liu, <em>et al</em></div>
        <div class="paper-conf"><em><font color="#000000"><b>1st Place</b></font> In Proceedings of the IEEE Computer Vision and Pattern Recognition (<font color="#000000"><b>CVPR</b></font>) Workshops, 2024</em></div>
      </div>
    </div>

    <hr class="publication-hr">

    <div class="row">
      <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <img class="responsive-img" src="./data/visdrone2023.jpg" style="width:320px;height:160px;" align="center">
      </div>

      <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
        <div class="paper-title"><a href="http://aiskyeye.com/evaluate/leaderboard_2023/">ICCV 2023 VisDrone Challenge</a> <img class="responsive-img icon" src="./data/1.png"> </div>
          <div class="paper-task">Track 1: Object Detection in Image</div>

        <div class="paper-author"><font color="#000000"><b>Xiaoqiang Lu</b></font>, Licheng Jiao, Zhongjian Huang, Yuting Yang, <em>et al</em></div>
        <div class="paper-conf"><em><font color="#000000"><b>1st Place</b></font> In Proceedings of the IEEE International Conference on Computer Vision (<font color="#000000"><b>ICCV</b></font>) Workshops, 2023</em></div>
      </div>
    </div>

    <hr class="publication-hr">

    <div class="row">
      <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <img class="responsive-img" src="./data/rod.png" style="width:320px;height:160px;" align="center">
      </div>

      <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
        <div class="paper-title"><a href="https://wvcl.vis.xyz/challenges#results">ICCV 2023 Visual Continual Learning Challenges</a> <img class="responsive-img icon" src="./data/1.png"> </div>
          <div class="paper-task">Track C: Robust RAW Object Detection</div>

        <div class="paper-author"><font color="#000000"><b>Xiaoqiang Lu</b>, Licheng Jiao, <em>et al</em></font></div>
        <div class="paper-conf"><em><font color="#000000"><b>1st Place</b></font> In Proceedings of the IEEE International Conference on Computer Vision (<font color="#000000"><b>ICCV</b></font>) Workshops, 2023</em></div>
      </div>
    </div>

    <hr class="publication-hr">

    <div class="row">
      <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <img class="responsive-img" src="./data/cvppa.png" style="width:320px;height:160px;" align="center">
      </div>

      <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
        <div class="paper-title"><a href="https://cvppa2023.github.io/challenges/">ICCV 2023 Computer Vision in Plant Phenotyping and Agriculture Challenges</a> <img class="responsive-img icon" src="./data/1.png"></div>
          <div class="paper-task">Track 1: Hierarchical Panoptic Segmentation of Crops and Weeds</div>

        <div class="paper-author"><font color="#000000"><b>Xiaoqiang Lu</b></font>, Licheng Jiao, <em>et al</em></div>
        <div class="paper-conf"><em><font color="#000000"><b>1st Place</b></font> In Proceedings of the IEEE International Conference on Computer Vision (<font color="#000000"><b>ICCV</b></font>) Workshops, 2023</em></div>
      </div>
    </div>

    <hr class="publication-hr">

    <div class="row">
      <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <img class="responsive-img" src="./data/acdc.png" style="width:320px;height:160px;" align="center">
      </div>

      <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
        <div class="paper-title"><a href="https://acdc.vision.ee.ethz.ch/news/">CVPR 2023 ACDC Challenge</a> <img class="responsive-img icon" src="./data/1.png"></div>
          <div class="paper-task">Track 4: Normal-to-adverse Domain Adaptation of Object Detection</div>

        <div class="paper-author"><font color="#000000"><b>Xiaoqiang Lu</b></font>, Licheng Jiao, <em>et al</em></div>
        <div class="paper-conf"><em><font color="#000000"><b>1st Place</b></font> In Proceedings of the IEEE Computer Vision and Pattern Recognition (<font color="#000000"><b>CVPR</b></font>) Workshops, 2023</em></div>
      </div>
    </div>

    <hr class="publication-hr">

    <div class="row">
      <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <img class="responsive-img" src="./data/vizwiz_2023.png" style="width:320px;height:160px;" align="center">
      </div>

      <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
        <div class="paper-title"><a href="https://vizwiz.org/workshops/2023-workshop/">CVPR 2023 VizWiz Grand Challenge</a> <img class="responsive-img icon" src="./data/1.png"></div>
          <div class="paper-task">Track 1: Visual Question Answering</div>

        <div class="paper-author"><font color="#000000"><b>Xiaoqiang Lu</b></font>, Licheng Jiao, <em>et al</em></div>
        <div class="paper-conf"><em><font color="#000000"><b>1st Place</b></font> In Proceedings of the IEEE Computer Vision and Pattern Recognition (<font color="#000000"><b>CVPR</b></font>) Workshops, 2023</em></div>
      </div>
    </div>

    <hr class="publication-hr">

    <div class="row">
      <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <img class="responsive-img" src="./data/vipriors_eccv2022.png" style="width:320px;height:160px;" align="center">
      </div>

      <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
        <div class="paper-title"><a href="https://vipriors.github.io/2022/challenges/">ECCV 2022 Visual Inductive Priors for Data-Efficient Computer Vision Challenges</a> <img class="responsive-img icon" src="./data/1.png"></div>
          <div class="paper-task">Track: Object Detection</div>

        <div class="paper-author"><font color="#000000"><b>Xiaoqiang Lu</b></font>, Yuting Yang, Zhongjian Huang, <em>et al</em></div>
        <div class="paper-conf"><em><font color="#000000"><b>1st Place</b></font> In Proceedings of the European Conference on Computer Vision (<font color="#000000"><b>ECCV</b></font>) Workshops, 2022</em></div>
      </div>
    </div>

    <hr class="publication-hr">

    <div class="row">
      <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <img class="responsive-img" src="./data/chalearn.png" style="width:320px;height:160px;" align="center">
      </div>

      <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
        <div class="paper-title"><a href="https://chalearnlap.cvc.uab.cat/challenge/51/track/47/result/">ECCV 2022 ChaLearn Seasons in Drift Challenge</a> <img class="responsive-img icon" src="./data/1.png"></div>
          <div class="paper-task">Track 1: Detection at Day Level</div>

        <div class="paper-author"><font color="#000000"><b>Xiaoqiang Lu</b></font>, Tong Gou, Zhongjian Huang, Yuting Yang, <em>et al</em></div>
        <div class="paper-conf"><em><font color="#000000"><b>1st Place</b></font> In Proceedings of the European Conference on Computer Vision (<font color="#000000"><b>ECCV</b></font>) Workshops, 2022</em></div>
      </div>
    </div>

    <hr class="publication-hr">

    <div class="row">
      <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <img class="responsive-img" src="./data/chalearn.png" style="width:320px;height:160px;" align="center">
      </div>

      <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
        <div class="paper-title"><a href="https://chalearnlap.cvc.uab.cat/challenge/51/track/48/result/">ECCV 2022 ChaLearn Seasons in Drift Challenge</a> <img class="responsive-img icon" src="./data/1.png"></div>
          <div class="paper-task">Track 2: Detection at Week Level</div>

        <div class="paper-author"><font color="#000000"><b>Xiaoqiang Lu</b></font>, Tong Gou, Zhongjian Huang, Yuting Yang, <em>et al</em></div>
        <div class="paper-conf"><em><font color="#000000"><b>1st Place</b></font> In Proceedings of the European Conference on Computer Vision (<font color="#000000"><b>ECCV</b></font>) Workshops, 2022</em></div>
      </div>
    </div>

    <hr class="publication-hr">

    <div class="row">
      <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <img class="responsive-img" src="./data/chalearn.png" style="width:320px;height:160px;" align="center">
      </div>

      <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
        <div class="paper-title"><a href="https://chalearnlap.cvc.uab.cat/challenge/51/track/49/result/">ECCV 2022 ChaLearn Seasons in Drift Challenge</a> <img class="responsive-img icon" src="./data/1.png"></div>
          <div class="paper-task">Track 3: Detection at Month Level</div>

        <div class="paper-author"><font color="#000000"><b>Xiaoqiang Lu</b></font>, Tong Gou, Zhongjian Huang, Yuting Yang, <em>et al</em></div>
        <div class="paper-conf"><em><font color="#000000"><b>1st Place</b></font> In Proceedings of the European Conference on Computer Vision (<font color="#000000"><b>ECCV</b></font>) Workshops, 2022</em></div>
      </div>
    </div>

    <hr class="publication-hr">

    <div class="row">
      <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <img class="responsive-img" src="./data/fisheye.png" style="width:320px;height:160px;" align="center">
      </div>

      <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
        <div class="paper-title"><a href="https://sites.google.com/view/omnicv2022/challenge">CVPR 2022 Woodscape OmniCV Challenge</a> <img class="responsive-img icon" src="./data/1.png"></div>
          <div class="paper-task">Track: Fisheye Object Detection for Autonomous Driving</div>

        <div class="paper-author"><font color="#000000"><b>Xiaoqiang Lu</b></font>, <em>et al</em></div>
        <div class="paper-conf"><em><font color="#000000"><b>1st Place</b></font> In Proceedings of the IEEE Computer Vision and Pattern Recognition (<font color="#000000"><b>CVPR</b></font>) Workshops, 2022</em></div>
      </div>
    </div>

    <hr class="publication-hr">

    <div class="row">
      <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <img class="responsive-img" src="./data/dfc_2022.png" style="width:320px;height:160px;" align="center">
      </div>

      <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
        <div class="paper-title"><a href="https://www.grss-ieee.org/community/technical-committees/2022-ieee-grss-data-fusion-contest-semi-supervised-learning-for-land-cover-classification/">IEEE GRSS 2022 Data Fusion Contest</a> <img class="responsive-img icon" src="./data/1.png"></div>
          <div class="paper-task">Track SLM: Semi-supervised Learning for Land Cover Classification</div>

        <div class="paper-author"><font color="#000000"><b>Xiaoqiang Lu</b></font>, Guojin Cao, Tong Gou</div>
        <div class="paper-conf"><em><font color="#000000"><b>1st Place</b></font> In IEEE International Geoscience and Remote Sensing Symposium (<font color="#000000"><b>IGARSS</b></font>), 2022</em></div>
      </div>
    </div>

    <hr class="publication-hr">

    <div class="row">
      <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <img class="responsive-img" src="./data/vipriors_iccv2021.png" style="width:320px;height:160px;" align="center">
      </div>

      <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
        <div class="paper-title"><a href="https://vipriors.github.io/2021/challenges/">ICCV 2021 Visual Inductive Priors for Data-Efficient Computer Vision Challenges</a> <img class="responsive-img icon" src="./data/1.png"></div>
          <div class="paper-task">Track: Object Detection</div>

        <div class="paper-author"><font color="#000000"><b>Xiaoqiang Lu</b></font>, Guojin Cao, <em>et al</em></div>
        <div class="paper-conf"><em><font color="#000000"><b>1st Place</b></font> In Proceedings of the IEEE International Conference on Computer Vision (<font color="#000000"><b>ICCV</b></font>) Workshops, 2021</em></div>
      </div>
    </div>

    <hr class="publication-hr">

    <div class="row">
      <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <img class="responsive-img" src="./data/floodnet.png" style="width:320px;height:160px;" align="center">
      </div>

      <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
        <div class="paper-title"><a href="http://www.classic.grss-ieee.org/earthvision2021/challenge.html">CVPR 2021 FloodNet Challenge @ EARTHVISION 2021</a> <img class="responsive-img icon" src="./data/1.png"></div>
          <div class="paper-task">Track 1: Semi-supervised Image Classification and Semantic Segmentation</div>

        <div class="paper-author"><font color="#000000"><b>Xiaoqiang Lu</b></font>, Guojin Cao, Luyao Nie, Yuting Yang</div>
        <div class="paper-conf"><em><font color="#000000"><b>1st Place</b></font> In Proceedings of the IEEE Computer Vision and Pattern Recognition (<font color="#000000"><b>CVPR</b></font>) Workshops, 2021</em></div>
      </div>
    </div>

    <hr class="publication-hr">

    <div class="row">
      <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <img class="responsive-img" src="./data/ava24.png" style="width:320px;height:160px;" align="center">
      </div>

      <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
        <div class="paper-title"><a href="https://accessibility-cv.github.io/index_2024">CVPR 2024 AVA: Accessibility, Vision, and Autonomy Meet Challenges</a> <img class="responsive-img icon" src="./data/2.png"></div>
          <div class="paper-task">Track: Object Detection</div>

        <div class="paper-author"><font color="#000000"><b>Xiaoqiang Lu</b></font>, Licheng Jiao, Xu Liu, <em>et al</em></div>
        <div class="paper-conf"><em><font color="#000000"><b>2nd Place</b></font> In Proceedings of the IEEE Computer Vision and Pattern Recognition (<font color="#000000"><b>CVPR</b></font>) Workshops, 2024</em></div>
      </div>
    </div>

    <hr class="publication-hr">

    <div class="row">
      <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <img class="responsive-img" src="./data/vipriors_iccv2023.png" style="width:320px;height:160px;" align="center">
      </div>

      <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
        <div class="paper-title"><a href="https://vipriors.github.io/challenges/">ICCV 2023 Visual Inductive Priors for Data-Efficient Computer Vision Challenges</a> <img class="responsive-img icon" src="./data/2.png"></div>
          <div class="paper-task">Track: Object Detection</div>

        <div class="paper-author"><font color="#000000"><b>Xiaoqiang Lu</b></font>, Jiaxuan Zhao, Yuting Yang, Zhongjian Huang, <em>et al</em></div>
        <div class="paper-conf"><em><font color="#000000"><b>2nd Place</b></font> In Proceedings of the IEEE International Conference on Computer Vision (<font color="#000000"><b>ICCV</b></font>) Workshops, 2023</em></div>
      </div>
    </div>

    <hr class="publication-hr">

    <div class="row">
      <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <img class="responsive-img" src="./data/vipriors_iccv2023.png" style="width:320px;height:160px;" align="center">
      </div>

      <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
        <div class="paper-title"><a href="https://vipriors.github.io/challenges/">ICCV 2023 Visual Inductive Priors for Data-Efficient Computer Vision Challenges</a> <img class="responsive-img icon" src="./data/2.png"></div>
          <div class="paper-task">Track: Instance Segmentation</div>

        <div class="paper-author"><font color="#000000"><b>Xiaoqiang Lu</b></font>, Yuting Yang, Zhongjian Huang, Jiaxuan Zhao, <em>et al</em></div>
        <div class="paper-conf"><em><font color="#000000"><b>2nd Place</b></font> In Proceedings of the IEEE International Conference on Computer Vision (<font color="#000000"><b>ICCV</b></font>) Workshops, 2023</em></div>
      </div>
    </div>

    <hr class="publication-hr">

    <div class="row">
      <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <img class="responsive-img" src="./data/ug2+.png" style="width:320px;height:160px;" align="center">
      </div>

      <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
        <div class="paper-title"><a href="https://cvpr2023.ug2challenge.org/">CVPR 2023 UG2+ Challenge</a> <img class="responsive-img icon" src="./data/2.png"></div>
          <div class="paper-task">Track 1: Object Detection in Haze</div>

        <div class="paper-author"><font color="#000000"><b>Xiaoqiang Lu</b></font>, Yuting Yang, Zhongjian Huang, <em>et al</em></div>
        <div class="paper-conf"><em><font color="#000000"><b>2nd Place</b></font> In Proceedings of the IEEE Computer Vision and Pattern Recognition (<font color="#000000"><b>CVPR</b></font>) Workshops, 2023</em></div>
      </div>
    </div>

    <hr class="publication-hr">

    <div class="row">
      <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <img class="responsive-img" src="./data/dfc23.png" style="width:320px;height:160px;" align="center">
      </div>

      <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
        <div class="paper-title"><a href="https://codalab.lisn.upsaclay.fr/competitions/8987#results">IEEE GRSS 2023 Data Fusion Contest</a> <img class="responsive-img icon" src="./data/2.png"></div>
          <div class="paper-task">Track 1: Building Detection and Roof Type Classification</div>

        <div class="paper-author"><font color="#000000"><b>Xiaoqiang Lu</b></font>, Licheng Jiao, Qiong Liu, <em>et al</em></div>
        <div class="paper-conf"><em><font color="#000000"><b>2nd Place</b></font> In IEEE International Geoscience and Remote Sensing Symposium (<font color="#000000"><b>IGARSS</b></font>), 2023</em></div>
      </div>
    </div>

    <hr class="publication-hr">

    <div class="row">
      <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <img class="responsive-img" src="./data/dfc23.png" style="width:320px;height:160px;" align="center">
      </div>

      <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
        <div class="paper-title"><a href="https://codalab.lisn.upsaclay.fr/competitions/8988#results">IEEE GRSS 2023 Data Fusion Contest</a> <img class="responsive-img icon" src="./data/2.png"></div>
          <div class="paper-task">Track 2: Multi-Task Learning of Joint Building Extraction and Height Estimation</div>

        <div class="paper-author"><font color="#000000"><b>Xiaoqiang Lu</b></font>, Licheng Jiao, Qiong Liu, <em>et al</em></div>
        <div class="paper-conf"><em><font color="#000000"><b>2nd Place</b></font> In IEEE International Geoscience and Remote Sensing Symposium (<font color="#000000"><b>IGARSS</b></font>), 2023</em></div>
      </div>
    </div>

    <hr class="publication-hr">

    <div class="row">
      <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <img class="responsive-img" src="./data/vipriors_eccv2022.png" style="width:320px;height:160px;" align="center">
      </div>

      <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
        <div class="paper-title"><a href="https://vipriors.github.io/2022/challenges/">ECCV 2022 Visual Inductive Priors for Data-Efficient Computer Vision Challenges</a> <img class="responsive-img icon" src="./data/2.png"></div>
          <div class="paper-task">Track: Image Classification</div>

        <div class="paper-author"><font color="#000000"><b>Xiaoqiang Lu</b></font>, Zhongjian Huang, Yuting Yang, <em>et al</em></div>
        <div class="paper-conf"><em><font color="#000000"><b>2nd Place</b></font> In Proceedings of the European Conference on Computer Vision (<font color="#000000"><b>ECCV</b></font>) Workshops, 2022</em></div>
      </div>
    </div>

    <hr class="publication-hr">

    <div class="row">
      <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <img class="responsive-img" src="./data/vipriors_eccv2022.png" style="width:320px;height:160px;" align="center">
      </div>

      <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
        <div class="paper-title"><a href="https://vipriors.github.io/2022/challenges/">ECCV 2022 Visual Inductive Priors for Data-Efficient Computer Vision Challenges</a> <img class="responsive-img icon" src="./data/2.png"></div>
          <div class="paper-task">Track: Instance Segmentation</div>

        <div class="paper-author"><font color="#000000"><b>Xiaoqiang Lu</b></font>, Yuting Yang, Zhongjian Huang</div>
        <div class="paper-conf"><em><font color="#000000"><b>2nd Place</b></font> In Proceedings of the European Conference on Computer Vision (<font color="#000000"><b>ECCV</b></font>) Workshops, 2022</em></div>
      </div>
    </div>

    <hr class="publication-hr">

    <div class="row">
      <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <img class="responsive-img" src="./data/sslad_eccv2022.png" style="width:320px;height:160px;" align="center">
      </div>

      <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
        <div class="paper-title"><a href="https://sslad2022.github.io/pages/challenge.html">ECCV 2022 Self-supervised Learning for Next-Generation Industry-level Autonomous Driving Challenges</a> <img class="responsive-img icon" src="./data/2.png"></div>
          <div class="paper-task">Track 1: 2D Object Detection</div>

        <div class="paper-author"><font color="#000000"><b>Xiaoqiang Lu</b></font>, Yuting Yang, <em>et al</em></div>
        <div class="paper-conf"><em><font color="#000000"><b>2nd Place</b></font> In Proceedings of the European Conference on Computer Vision (<font color="#000000"><b>ECCV</b></font>) Workshops, 2022</em></div>
      </div>
    </div>

    <hr class="publication-hr">

    <div class="row">
      <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <img class="responsive-img" src="./data/sslad_eccv2022.png" style="width:320px;height:160px;" align="center">
      </div>

      <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
        <div class="paper-title"><a href="https://sslad2022.github.io/pages/challenge.html">ECCV 2022 Self-supervised Learning for Next-Generation Industry-level Autonomous Driving Challenges</a> <img class="responsive-img icon" src="./data/2.png"></div>
          <div class="paper-task">Track 3: Corner Case Detection</div>

        <div class="paper-author"><font color="#000000"><b>Xiaoqiang Lu</b></font>, Yuting Yang, <em>et al</em></div>
        <div class="paper-conf"><em><font color="#000000"><b>2nd Place</b></font> In Proceedings of the European Conference on Computer Vision (<font color="#000000"><b>ECCV</b></font>) Workshops, 2022</em></div>
      </div>
    </div>

    <hr class="publication-hr">

    <div class="row">
      <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <img class="responsive-img" src="./data/visdrone2021.jpg" style="width:320px;height:160px;" align="center">
      </div>

      <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
        <div class="paper-title"><a href="http://aiskyeye.com/visdrone-2021-leaderboard/">ICCV 2021 VisDrone Challenge</a> <img class="responsive-img icon" src="./data/2.png"></div>
          <div class="paper-task">Track 1: Object Detection in Image</div>

        <div class="paper-author"><font color="#000000"><b>Xiaoqiang Lu</b></font>, Guojin Cao, <em>et al</em></div>
        <div class="paper-conf"><em><font color="#000000"><b>2nd Place</b></font> In Proceedings of the IEEE International Conference on Computer Vision (<font color="#000000"><b>ICCV</b></font>) Workshops, 2021</em></div>
      </div>
    </div>

    <hr class="publication-hr">

    <div class="row">
      <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <img class="responsive-img" src="./data/agrivision.png" style="width:320px;height:160px;" align="center">
      </div>

      <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
        <div class="paper-title"><a href="https://www.agriculture-vision.com/agriculture-vision-2024/prize-challenge-2024">CVPR 2024 Agriculture-Vision Prize Challenge</a> <img class="responsive-img icon" src="./data/3.png"></div>
          <div class="paper-task">Track: Agricultural Pattern Recognition from Aerial Images</div>

        <div class="paper-author"><font color="#000000"><b>Xiaoqiang Lu</b></font>, Xu Liu, Lingling Li<em>et al</em></div>
        <div class="paper-conf"><em><font color="#000000"><b>3rd Place</b></font> In Proceedings of the IEEE Computer Vision and Pattern Recognition (<font color="#000000"><b>CVPR</b></font>) Workshops, 2024</em></div>
      </div>
    </div>

    <hr class="publication-hr">

    <div class="row">
      <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <img class="responsive-img" src="./data/dfc24.png" style="width:320px;height:160px;" align="center">
      </div>

      <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
        <div class="paper-title"><a href="https://www.grss-ieee.org/community/technical-committees/2024-ieee-grss-data-fusion-contest-flood-rapid-mapping/">IEEE GRSS 2024 Data Fusion Contest</a> <img class="responsive-img icon" src="./data/2.png"></div>
          <div class="paper-task">Track 2: Flood Rapid Mapping with Optical Data</div>

        <div class="paper-author"><font color="#000000"><b>Xiaoqiang Lu</b></font>, Tong Gou, Zhongjian Huang, <em>et al</em></div>
        <div class="paper-conf"><em><font color="#000000"><b>3rd Place</b></font> In IEEE International Geoscience and Remote Sensing Symposium (<font color="#000000"><b>IGARSS</b></font>), 2024</em></div>
      </div>
    </div>

    <hr class="publication-hr">

    <div class="row">
      <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <img class="responsive-img" src="./data/vizwiz_2022.png" style="width:320px;height:160px;" align="center">
      </div>

      <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
        <div class="paper-title"><a href="https://vizwiz.org/workshops/2022-workshop/">CVPR 2022 VizWiz Grand Challenge</a> <img class="responsive-img icon" src="./data/3.png"></div>
          <div class="paper-task">Track 1: Visual Question Answering</div>

        <div class="paper-author"><font color="#000000"><b>Xiaoqiang Lu</b></font>, <em>et al</em></div>
        <div class="paper-conf"><em><font color="#000000"><b>3rd Place</b></font> In Proceedings of the IEEE Computer Vision and Pattern Recognition (<font color="#000000"><b>CVPR</b></font>) Workshops, 2022</em></div>
      </div>
    </div>

    <hr class="publication-hr">

    <div class="row">
      <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <img class="responsive-img" src="./data/sslad_iccv2021.png" style="width:320px;height:160px;" align="center">
      </div>

      <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
        <div class="paper-title"><a href="https://sslad2021.github.io/pages/challenge.html">ICCV 2021 Self-supervised Learning for Next-Generation Industry-level Autonomous Driving Challenges</a> <img class="responsive-img icon" src="./data/3.png"></div>
          <div class="paper-task">Track 1: 2D Object Detection</div>

        <div class="paper-author"><font color="#000000"><b>Xiaoqiang Lu</b></font>, Guojin Cao, <em>et al</em></div>
        <div class="paper-conf"><em><font color="#000000"><b>3rd Place</b></font> In Proceedings of the IEEE International Conference on Computer Vision (<font color="#000000"><b>ICCV</b></font>) Workshops, 2021</em></div>
      </div>
    </div>

    <hr class="publication-hr">

  </div>

</div>


<div class="section education-section scrollspy" id="education">
  <div class="row container">
    <div class="row">
      <div class="title">🎓 Education</div>
      <hr>
    </div>

    <div class="row">
        <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <a href="https://www.xidian.edu.cn/" target="_blank">
            <img src="./data/xidian.png" style="width:240px;height:80px;" align="center" class="img-responsive edu-img">
          </a>
        </div>

        <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <p></p>
          <p></p>
          <p></p>
          <div class="degree"><b>Ph.D.</b> Student at <a href="https://ipiu.xidian.edu.cn/">IPIU</a>, <a href="https://sai.xidian.edu.cn/">School of Artificial Intelligence</a>, <a href="https://www.xidian.edu.cn/">Xidian University</a>, Xi'an, China</div>
          <div class="date">Sep. 2022 - Now, Supervised by Prof. <a href="https://scholar.google.com/citations?user=FZbrL2YAAAAJ&hl=zh-CN">Licheng Jiao</a></div>
        </div>
    </div>

    <div class="row">
        <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <a href="https://www.xidian.edu.cn/" target="_blank">
            <img src="./data/xidian.png" style="width:240px;height:80px;" align="center" class="img-responsive edu-img">
          </a>
        </div>

        <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <p></p>
          <p></p>
          <p></p>
          <div class="degree"></div>
          <div class="degree"><b>M.S.</b> Student at <a href="https://ipiu.xidian.edu.cn/">IPIU</a>, <a href="https://sai.xidian.edu.cn/">School of Artificial Intelligence</a>, <a href="https://www.xidian.edu.cn/">Xidian University</a>, Xi'an, China</div>
          <div class="date">Sep. 2020 - July 2022, Supervised by Prof. <a href="https://scholar.google.com/citations?user=FZbrL2YAAAAJ&hl=zh-CN">Licheng Jiao</a></div>
        </div>
    </div>

    <div class="row">
        <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <a href="https://www.xidian.edu.cn/" target="_blank">
            <img src="./data/xidian.png" style="width:240px;height:80px;" align="center" class="img-responsive edu-img">
          </a>
        </div>

        <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <p></p>
          <p></p>
          <p></p>
          <div class="degree"></div>
          <div class="degree"><b>B.E.</b> Student at <a href="https://see.xidian.edu.cn/">School of Electronic Engineering</a>, <a href="https://www.xidian.edu.cn/">Xidian University</a>, Xi'an, China</div>
          <div class="date">Sep. 2016 - July 2020</div>
        </div>
    </div>

  </div>
</div>


<div class="section awards-section scrollspy" id="awards">
  <div class="row container">
    <div class="row">
      <div class="title">🎖 Awards</div>      
      <hr>
      <ul>
        <li>  • The Youth Talent Support Program of the China Association for Science and Technology for PhD Students, 2024</li>
        <li>  • Outstanding Doctoral Dissertation Support Funding of Xidian University, 2024</li>
        <li>  • HUAWEI Scholarship, 1/3, 2024</li>
        <li>  • Outstanding Graduate Student of Xidian University, 2023-2024</li>
        <li>  • <font color="#000000"><b>National Scholarship</b></font> (For Ph.D. Students), Top-1 in SAI, 2023</li>
        <li>  • Outstanding Graduate Student of Xidian University, 2022-2023</li>
        <li>  • <font color="#000000"><b>National Scholarship</b></font> (For Master Students), <a href="https://news.xidian.edu.cn/info/2106/221647.htm"> Top-1 in GIT</a>, 2021</li>
        <li>  • Outstanding Graduate Student of Xidian University, 2020-2021</li>
      </ul>
    </div>
  </div>
</div>

</div>
</body>
</html>
