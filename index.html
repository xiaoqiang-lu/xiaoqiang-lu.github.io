<!DOCTYPE HTML>
<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?031f1c7d5b09cd718f3482df88fc8aa4";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Xiaoqiang Lu</title>

  <meta name="author" content="Xiaoqiang Lu">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/seal_icon.png">
  <style>
    ul{
      list-style-type: decimal;
    }
  </style>
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Xiaoqiang Lu</name>
              </p>
              <p>I currently pursuing the Ph.D. degree with the <a href="https://ipiu.xidian.edu.cn/">Key Laboratory of Intelligent Perception and Image Understanding of Ministry of Education</a>, <a href="https://sai.xidian.edu.cn/">School of Artificial Intelligence</a>, <a href="https://www.xidian.edu.cn/">Xidian University</a>, supervised by Prof. <a href="https://scholar.google.com/citations?user=FZbrL2YAAAAJ&hl=zh-CN">Licheng Jiao</a></li>. Prior to this, I received my B.S. degree in Information Countermeasure Technique from Xidian University in 2020. Currently, my research interests mainly lie in semi-supervised learning, semantic segmentation, object detection, vision-language learning, and remote sensing data interpretation.
              </p>
              <p style="text-align:center">
                <a href="mailto:xqlu@stu.xidian.edu.cn">Email</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=u8fIK3cAAAAJ&hl=zh-CN">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/xiaoqiang-lu">Github</a>
              </p>
            </td>
          </tr>
        </tbody></table>

<!--        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>-->
<!--            <tr>-->
<!--            <td style="padding:20px;width:100%;vertical-align:middle">-->
<!--              <heading>News</heading>-->
<!--              <p>-->
<!--                <li>[04/2022] I join SenseTime as a research intern.-->
<!--                <li>[03/2022] One paper on <a href="https://arxiv.org/abs/2106.05095">semi-supervised semantic segmentation</a> is accepted by CVPR 2022.</li>-->
<!--                <li>[10/2021] I am awarded the China National Scholarship.</li>-->
<!--                <li>[07/2021] One paper on <a href="https://arxiv.org/abs/2103.15402">few-shot segmentation</a> is accepted by ICCV 2021 as an oral presentation.</li>-->
<!--              </p>-->
<!--            </td>-->
<!--          </tr>-->
<!--        </tbody></table>-->


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Publications</heading>
              <p>
                <li>Semi-Supervised Landcover Classification with Adaptive Pixel-Rebalancing Self-Training. <em> IEEE International Geoscience and Remote Sensing Symposium (<strong>IGARSS</strong>)</em>, 2022. <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9884933">[PDF]</a></li>
                <li>Simple and Efficient: A Semisupervised Learning Framework for Remote Sensing Image Semantic Segmentation. <em> IEEE Transactions on Geoscience and Remote Sensing (<strong>TGRS</strong>)</em>, 2022. </a></li>
              </p>
            </td>
          </tr>
        </tbody></table>

<!--          <tr>-->
<!--            <td style="padding:20px;width:25%;vertical-align:middle">-->
<!--              <img src='data/miningfss.png' width="180">-->
<!--            </td>-->
<!--            <td style="padding:20px;width:75%;vertical-align:middle">-->
<!--              <papertitle>Mining Latent Classes for Few-shot Segmentation</papertitle>-->
<!--              <br>-->
<!--              <strong>Lihe Yang</strong>,-->
<!--              <a href="https://scholar.google.com.au/citations?user=Q-UjnzEAAAAJ&hl=en">Wei Zhuo</a>,-->
<!--              <a href="http://palm.seu.edu.cn/qilei/">Lei Qi</a>,-->
<!--              <a href="https://cs.nju.edu.cn/shiyh/index.htm">Yinghuan Shi</a>,-->
<!--              <a href="https://scholar.google.com/citations?user=k0jjQo8AAAAJ&hl=zh-CN">Yang Gao</a>-->
<!--              <br>-->
<!--              <em>IEEE International Conference on Computer Vision (<strong>ICCV</strong>)</em> <font color="red"><strong>(Oral Presentation, 3%)</strong></font>, 2021-->
<!--              <br>-->
<!--              <a href="https://arxiv.org/abs/2103.15402">[PDF]</a>-->
<!--              <a href="https://github.com/LiheYoung/MiningFSS">[Code]</a>-->
<!--              <p></p>-->
<!--              <p>Propose a novel few-shot segmentation framework to address the feature undermining issue and prototype bias issue.</p>-->
<!--            </td>-->
<!--          </tr>-->
<!--  </tbody></table>-->

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Experience</heading>
              <p>
                <li>Sep. 2022 - Now, Pursuing Ph.D. degree at <a href="https://ipiu.xidian.edu.cn/">IPIU</a>, <a href="https://sai.xidian.edu.cn/">School of Artificial Intelligence</a>, <a href="https://www.xidian.edu.cn/">Xidian University</a>, supervised by Prof. <a href="https://scholar.google.com/citations?user=FZbrL2YAAAAJ&hl=zh-CN">Licheng Jiao</a>.</li>
                <li>Sep. 2020 - Jun. 2022, M.S. degree student at <a href="https://ipiu.xidian.edu.cn/">IPIU</a>, <a href="https://sai.xidian.edu.cn/">School of Artificial Intelligence</a>, <a href="https://www.xidian.edu.cn/">Xidian University</a>, supervised by Prof. <a href="https://scholar.google.com/citations?user=FZbrL2YAAAAJ&hl=zh-CN">Licheng Jiao</a>.</li>
                <li>Sep. 2016 - Jun. 2020, B.S. degree student at <a href="https://see.xidian.edu.cn/">School of Electronic Engineering</a>, <a href="https://www.xidian.edu.cn/">Xidian University</a>.</li>
              </p>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Contests</heading>
              <p>
                <li><strong>1st Place</strong>, CVPR 2021 FloodNet Challenge @ EARTHVISION 2021 - Track 1 <a href="https://competitions.codalab.org/competitions/30290#results">[Link]</a> (First author)</li>
                <li><strong>1st Place</strong>, ICCV 2021 VIPriors Object Detection Challenge <a href="https://vipriors.github.io/2021/challenges/">[Link]</a> (First author)</li>
                <li><strong>1st Place</strong>, 2022 IEEE GRSS Data Fusion Contest Track SLM <a href="https://www.grss-ieee.org/community/technical-committees/2022-ieee-grss-data-fusion-contest-semi-supervised-learning-for-land-cover-classification/">[Link]</a> (First author)</li>
                <li><strong>1st Place</strong>, CVPR 2022 Fisheye Object Detection Challenge for Autonomous Driving <a href="https://sites.google.com/view/omnicv2022/challenge">[Link]</a> (First author)</li>
                <li><strong>1st Place</strong>, ECCV 2022 ChaLearn Seasons in Drift Challenge (track 1: day level) <a href="https://chalearnlap.cvc.uab.cat/challenge/51/track/47/result/">[Link]</a> (First author)</li>
                <li><strong>1st Place</strong>, ECCV 2022 ChaLearn Seasons in Drift Challenge (track 1: week level) <a href="https://chalearnlap.cvc.uab.cat/challenge/51/track/48/result/">[Link]</a> (First author)</li>
                <li><strong>1st Place</strong>, ECCV 2022 ChaLearn Seasons in Drift Challenge (track 1: month level) <a href="https://chalearnlap.cvc.uab.cat/challenge/51/track/49/result/">[Link]</a> (First author)</li>
                <li><strong>1st Place</strong>, ECCV 2022 VIPriors Object Detection Challenge <a href="https://vipriors.github.io/challenges/">[Link]</a> (First author)</li>
                <li><strong>2nd Place</strong>, ICCV 2021 VisDrone Object Detection Challenge <a href="http://aiskyeye.com/visdrone-2021-leaderboard/">[Link]</a> (First author)</li>
                <li><strong>2nd Place</strong>, PRCV 2022 VisDrone Object Detection Challenge <a href="http://aiskyeye.com/visdrone-2021-leaderboard/">[Link]</a> (First author)</li>
                <li><strong>2nd Place</strong>, ECCV 2022 SSLAD Track 1 - 2D object detection <a href="https://codalab.lisn.upsaclay.fr/competitions/6163#results">[Link]</a> (First author)</li>
                <li><strong>2nd Place</strong>, ECCV 2022 SSLAD Track 3 - Corner Case Detection <a href="https://codalab.lisn.upsaclay.fr/competitions/6639">[Link]</a> (First author)</li>
                <li><strong>2nd Place</strong>, ECCV 2022 VIPriors Image Classification Challenge <a href="https://vipriors.github.io/challenges/">[Link]</a> (First author)</li>
                <li><strong>2nd Place</strong>, ECCV 2022 VIPriors Instance Segmentation Challenge <a href="https://vipriors.github.io/challenges/">[Link]</a> (First author)</li>
                <li><strong>3rd Place</strong>, ICCV 2021 SSLAD Track 1 - 2D object detection <a href="https://sslad2021.github.io/pages/challenge.html">[Link]</a> (First author)</li>
                <li><strong>3rd Place</strong>, CVPR 2022 VizWiz Visual Question Answering <a href="https://vizwiz.org/workshops/2022-workshop/">[Link]</a> (First author)</li>

              </p>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Honors and Awards</heading>
              <p>
                <li><strong>China National Scholarship</strong> (the highest scholarship for students studying in China), 2021</li>
                <li>Outstanding Graduate Student of Xidian University, 2021</li>
              </p>
            </td>
          </tr>
        </tbody></table>


<!--        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>-->
<!--            <tr>-->
<!--            <td style="padding:20px;width:100%;vertical-align:middle">-->
<!--              <heading>Services</heading>-->
<!--              <p>-->
<!--                <li>Reviewer for <a href="https://cvpr2022.thecvf.com/">CVPR 2022</a>, <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=5962385">TNNLS</a>, <a href="https://eccv2022.ecva.net/">ECCV 2022</a></li>-->
<!--              </p>-->
<!--            </td>-->
<!--          </tr>-->
<!--        </tbody></table>-->

      </td>
    </tr>
  </table>

</body>

</html>
